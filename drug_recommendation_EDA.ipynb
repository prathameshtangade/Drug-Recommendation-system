{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb68e759",
   "metadata": {
    "id": "bb68e759"
   },
   "source": [
    "# Drug Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeaaa98",
   "metadata": {
    "id": "ebeaaa98"
   },
   "source": [
    "### Problem Statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63581ae6",
   "metadata": {
    "id": "63581ae6"
   },
   "source": [
    "Build a Drug recommender system that recommends the most effective drug for the given condition based on the reviews of various drugs used for that condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5609b2f",
   "metadata": {
    "id": "b5609b2f"
   },
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd81563",
   "metadata": {
    "id": "5fd81563"
   },
   "source": [
    "- The dataset used is ‘UCI ML Drug Review Dataset’.\n",
    "- Data source: https://www.kaggle.com/datasets/jessicali9530/kuc-hackathon-winter-2018\n",
    "- Data will be provided in two files:\n",
    "<br>\n",
    "<b>drugsComTrain_raw.csv</b> contains 7 columns: uniqueID, drugName, condition, review, rating, date, usefulCount </br>\n",
    "<b>drugsComTest_raw.csv</b> contains same columns\n",
    "<br>\n",
    "Number of rows in Train dataset is - 161297 and Test dataset is - 53766\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175b4ef",
   "metadata": {
    "id": "d175b4ef"
   },
   "source": [
    "### Mapping the real-world problem to ML problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc5bc6",
   "metadata": {
    "id": "3ffc5bc6"
   },
   "source": [
    "<b>Objective</b>:Analyse a review and decide whether it is positive or negative.\n",
    "To determine the most effective drug to recommend, a recommendation score must be determined based on the classification of the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0167bb",
   "metadata": {
    "id": "5c0167bb"
   },
   "source": [
    "We can use the given ratings to classify the reviews. The target feature is created by classifying the reviews as positive with ratings 6-10 and negative with ratings 1-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7b9bb",
   "metadata": {
    "id": "f2f7b9bb"
   },
   "source": [
    "#### Type of Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323a9f8",
   "metadata": {
    "id": "2323a9f8"
   },
   "source": [
    "Here the reviews need to classified to Positive and Negative classes. Hence it is a Binary Classification Problem i.e. logistics regression problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8585c",
   "metadata": {
    "id": "07a8585c"
   },
   "source": [
    "#### Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba624753",
   "metadata": {
    "id": "ba624753"
   },
   "source": [
    "- F1 Score, Precision, Recall and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd1132",
   "metadata": {
    "id": "ecbd1132"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14dbbae1",
   "metadata": {
    "id": "14dbbae1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "import nltk\n",
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08335e55",
   "metadata": {
    "id": "08335e55"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\LENOVO\\\\Desktop\\\\drugsComTrain_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10572\\1059746753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\LENOVO\\Desktop\\drugsComTrain_raw.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\LENOVO\\Desktop\\drugsComTrain_raw.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\LENOVO\\\\Desktop\\\\drugsComTrain_raw.csv'"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv(r\"C:\\Users\\LENOVO\\Desktop\\drugsComTrain_raw.csv\")\n",
    "data_test = pd.read_csv(r\"C:\\Users\\LENOVO\\Desktop\\drugsComTrain_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db98f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24db98f5",
    "outputId": "ac48d679-0fac-4d12-b955-886abc2b0c4a"
   },
   "outputs": [],
   "source": [
    "print('Size of Train dataset is:',data_train.shape)\n",
    "print('Size of Test dataset is:',data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J9pG3bJK5R5m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9pG3bJK5R5m",
    "outputId": "ed43afa9-e1af-4750-d29f-691b4a568a6e"
   },
   "outputs": [],
   "source": [
    "data_train.values.shape[0] / data_test.values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50093a90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50093a90",
    "outputId": "8c74d13a-956e-4c25-e22f-0ad25b014a1f"
   },
   "outputs": [],
   "source": [
    "print('Columns of the dataset are:\\n',data_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd34011",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "bdd34011",
    "outputId": "3ca76011-3be7-423f-ec49-a4ef70786f67"
   },
   "outputs": [],
   "source": [
    "print('Overview of Train dataset:\\n')\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5fc946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "ca5fc946",
    "outputId": "d26a1e2d-f606-4594-b58c-300828714e87"
   },
   "outputs": [],
   "source": [
    "print('Overview of Test dataset:\\n')\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010db7c",
   "metadata": {
    "id": "6010db7c"
   },
   "source": [
    "- The Train and Test datasets has same features. In both of the datasets we need to preprocess and create the target variable.\n",
    "- So, we can concatenate the datasets and then preprocess and create the target variable accordingly.\n",
    "- Before the modelling the whole data can be splitted to train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11223181",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11223181",
    "outputId": "11789e13-ff1b-4349-f2c3-b69065355da0"
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data_train,data_test])\n",
    "print('The size of the combined data is:',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503eca4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "b503eca4",
    "outputId": "70152840-7d3c-4a5b-b930-c90eed27e71a"
   },
   "outputs": [],
   "source": [
    "# resetting the index after concatenation\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57783dcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57783dcb",
    "outputId": "13bc853e-3f71-407e-b6b2-c2bf81b1097c"
   },
   "outputs": [],
   "source": [
    "#checking for data types in the dataset\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e064c03",
   "metadata": {
    "id": "9e064c03"
   },
   "source": [
    "we have 3 numerical and 4 categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f97c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "a84f97c5",
    "outputId": "c4e6b32c-8bd9-49f0-ea63-e8d3795a7ad6"
   },
   "outputs": [],
   "source": [
    "#checking the description of the data\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5c09e2",
   "metadata": {
    "id": "ab5c09e2"
   },
   "source": [
    "average rating given is ~7 and upvotes as 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb51e72",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acb51e72",
    "outputId": "48f51c47-494c-4032-c331-4bf9c8e014a5"
   },
   "outputs": [],
   "source": [
    "#checking for Null values\n",
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef01c3",
   "metadata": {
    "id": "24ef01c3"
   },
   "source": [
    "Only condition feature has Null Values in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec44647",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ec44647",
    "outputId": "8b23736e-85c8-415d-96b6-94223e69be7e"
   },
   "outputs": [],
   "source": [
    "#checking for the number of null values and percentage in given dataset\n",
    "\n",
    "null_size = data.isnull().sum()['condition']\n",
    "print('Total null values are:',null_size)\n",
    "data_size = data.shape[0]\n",
    "print('Percentage of null values are:',(null_size/data_size)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd71742",
   "metadata": {
    "id": "8fd71742"
   },
   "source": [
    "- Null values are 0.5% of the total data points in Train and Test datasets. Hence we can drop the data points with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486d5f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c486d5f0",
    "outputId": "26074771-375c-4ce4-eefe-d45014ed01be"
   },
   "outputs": [],
   "source": [
    "# dropping the rows with null values\n",
    "\n",
    "data = data.dropna(axis=0)\n",
    "print('Size of the dataset after dropping null values:',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9403421",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9403421",
    "outputId": "fe96da7f-589f-430f-c74b-ba8d2fb8ba17"
   },
   "outputs": [],
   "source": [
    "# checking for number of unique conditions\n",
    "\n",
    "print('Number of unique conditions are:',data['condition'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yp31Kg6Z50hJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yp31Kg6Z50hJ",
    "outputId": "c944d94d-caa1-4a6d-d904-0c13e4becf1b"
   },
   "outputs": [],
   "source": [
    "data['condition'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb84b86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "dbb84b86",
    "outputId": "512c0250-a199-4f46-e0ee-001862fcc44c"
   },
   "outputs": [],
   "source": [
    "# plotting the top 10 conditions\n",
    "conditions = dict(data['condition'].value_counts())\n",
    "top_conditions = list(conditions.keys())[0:10]\n",
    "values = list(conditions.values())[0:10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.barplot(x=top_conditions,y=values,palette='summer')\n",
    "plt.title('Top 10 Conditions')\n",
    "plt.xlabel('Conditions')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b937f38f",
   "metadata": {
    "id": "b937f38f"
   },
   "source": [
    "- This plot shows that Birth Control is the top most people suffering condition  in given dataset followed by Depression, Pain, Anxiety and so on.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010e141",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "0010e141",
    "outputId": "0380d04a-bfa3-4382-a58c-e26f9e1d4fee"
   },
   "outputs": [],
   "source": [
    "# plotting number of drugs for top 10 condition\n",
    "val=[]\n",
    "for c in list(conditions.keys()):\n",
    "    val.append(data[data['condition']==c]['drugName'].nunique())\n",
    "\n",
    "drug_cond = dict(zip(list(conditions.keys()),val))\n",
    "\n",
    "top_conditions = list(drug_cond.keys())[0:10]\n",
    "values = list(drug_cond.values())[0:10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.barplot(x=top_conditions,y=values,palette='summer')\n",
    "plt.title('Number of Drugs for each Top 10 Conditions')\n",
    "plt.xlabel('Conditions')\n",
    "plt.ylabel('Count of Drugs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e7195",
   "metadata": {
    "id": "2b4e7195"
   },
   "source": [
    "- There are multiple drugs used by patients for each condition.\n",
    "- Pain and Birth Control conditions has highest number of different drugs available.  \n",
    "- This shows that it is necessary to analyze and recommend the most effective drug for each condition from the available drugs.\n",
    "- There are few conditions where only 1 drug is used by patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1275dcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "b1275dcd",
    "outputId": "67ba2f0d-213c-4a3a-fa63-a28ada7b7c0c"
   },
   "outputs": [],
   "source": [
    "#plotting the most used drug for Birth Control\n",
    "\n",
    "drugs_birth = dict(data[data['condition']=='Birth Control']['drugName'].value_counts())\n",
    "\n",
    "top_drugs = list(drugs_birth.keys())[0:10]\n",
    "values = list(drugs_birth.values())[0:10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.barplot(x=values,y=top_drugs,palette='summer')\n",
    "plt.title('Top 10 Drugs used for Birth Control')\n",
    "plt.ylabel('Drug Names')\n",
    "plt.xlabel('Count of Patients used')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340526a",
   "metadata": {
    "id": "7340526a"
   },
   "source": [
    "- This plot helps to understand, even if the condition has wide variety of drugs but the most used drugs are very few in number. Etonogestrol is most used drug by patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41961601",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "41961601",
    "outputId": "f95accda-9cbd-4577-f933-5bc9d5eb6129"
   },
   "outputs": [],
   "source": [
    "#plotting the most used drug for Pain\n",
    "\n",
    "drugs_pain = dict(data[data['condition']=='Pain']['drugName'].value_counts())\n",
    "top_drugs = list(drugs_pain.keys())[0:10]\n",
    "values = list(drugs_pain.values())[0:10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.barplot(x=values,y=top_drugs,palette='summer')\n",
    "plt.title('Top 10 Drugs used for Pain')\n",
    "plt.ylabel('Drug Names')\n",
    "plt.xlabel('Count of Patients used')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8ea9d",
   "metadata": {
    "id": "32d8ea9d"
   },
   "source": [
    "- Unlike above plot, here each drug has good number of usage count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82edd6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "2e82edd6",
    "outputId": "7a2bb58f-9ba1-40f1-edfc-24c372c0d517"
   },
   "outputs": [],
   "source": [
    "# plotting the top 10 drugs rated as 10\n",
    "drugs_rating = dict(data[data['rating']==10]['drugName'].value_counts())\n",
    "\n",
    "top_drugs = list(drugs_rating.keys())[0:10]\n",
    "values = list(drugs_rating.values())[0:10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.barplot(x=values,y=top_drugs,palette='summer')\n",
    "plt.title('Top 10 Drugs rated as 10')\n",
    "plt.ylabel('Drug Names')\n",
    "plt.xlabel('Count of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2980c46",
   "metadata": {
    "id": "a2980c46"
   },
   "source": [
    "- Birth Control and Weight Loss/Obesity drugs are top rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57a9c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "1e57a9c3",
    "outputId": "dc57cb3d-c591-473c-8bef-3474532bc0d2"
   },
   "outputs": [],
   "source": [
    "# plotting the top 10 drugs rated as 1\n",
    "drugs_rating = dict(data[data['rating']==1]['drugName'].value_counts())\n",
    "\n",
    "top_drugs = list(drugs_rating.keys())[0:10]\n",
    "values = list(drugs_rating.values())[0:10]\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.barplot(x=values,y=top_drugs,palette='summer')\n",
    "plt.title('Top 10 Drugs rated as 1')\n",
    "plt.ylabel('Drug Names')\n",
    "plt.xlabel('Count of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff62889",
   "metadata": {
    "id": "5ff62889"
   },
   "source": [
    "- The two Drugs Levonogestrol and Etonogestrel are in top 10 drugs with ratings '10' as well as '1'.\n",
    "- This implies there might be certain patients where the drugs were not effective or resulted in severe side effects which made it in less ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f3d9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "b50f3d9f",
    "outputId": "44bd1813-bc53-42dc-ef6a-0a63e719f5f1"
   },
   "outputs": [],
   "source": [
    "#plotting the distribution of ratings\n",
    "f,ax = plt.subplots(1,2,figsize=(16,8))\n",
    "ax1= sns.histplot(data['rating'],ax=ax[0])\n",
    "ax1.set_title('Count of Ratings')\n",
    "ax2= sns.distplot(data['rating'],ax=ax[1])\n",
    "ax2.set_title('Distribution of Ratings density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcbaeea",
   "metadata": {
    "id": "efcbaeea"
   },
   "source": [
    "- Most of the drugs are rated with 10,9,8 and 1 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50ef1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "id": "2c50ef1f",
    "outputId": "e2323dbe-6bd9-4a23-c2be-dd1c9f04cb1d"
   },
   "outputs": [],
   "source": [
    "#plotting the percentage distribution of ratings using pie chart\n",
    "\n",
    "ratings_count = dict(data['rating'].value_counts())\n",
    "count = list(ratings_count.values())\n",
    "labels = list(ratings_count.keys())\n",
    "plt.figure(figsize=(18,9))\n",
    "plt.pie(count,labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Pie Chart Representation of Ratings')\n",
    "plt.legend(title='Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6e68ff",
   "metadata": {
    "id": "ca6e68ff"
   },
   "source": [
    "We can see ~75% of drugs are rated with 10,9,8 and 1 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128ff14",
   "metadata": {
    "id": "3128ff14"
   },
   "outputs": [],
   "source": [
    "# chaning to date time format.\n",
    "\n",
    "data['date']= pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dbef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "id": "9c3dbef2",
    "outputId": "3166fae9-9275-41f2-ae49-b8417d90ff21"
   },
   "outputs": [],
   "source": [
    "#checking for ratings given in each year\n",
    "\n",
    "year_ratings = dict(data['date'].dt.year.value_counts())\n",
    "years = list(year_ratings.keys())\n",
    "values = list(year_ratings.values())\n",
    "plt.figure(figsize=(18,9))\n",
    "sns.barplot(x=years,y=values,palette='summer')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Count of Ratings')\n",
    "plt.title('Count of Ratings in each Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c423450",
   "metadata": {
    "id": "6c423450"
   },
   "source": [
    "- Patients starting giving reviews and ratings more from 2015.\n",
    "- We need to analyze if this date of entry has any impact on predicting the review sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a818a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "24a818a4",
    "outputId": "f8f77c93-8228-4307-f80f-60d08ffbff7e"
   },
   "outputs": [],
   "source": [
    "#checking the distribution of usefulCount feature\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "ax =sns.distplot(data['usefulCount'])\n",
    "\n",
    "plt.title('Distribution of usefulCount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af80a1",
   "metadata": {
    "id": "c3af80a1"
   },
   "source": [
    "- Maximum number of the drug review has not more than 200 upvotes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb2bedb",
   "metadata": {
    "id": "5cb2bedb"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e8d0b",
   "metadata": {
    "id": "d68e8d0b"
   },
   "outputs": [],
   "source": [
    "# creating the target feature using ratings\n",
    "# here 1 represents positive and 0 - represents negative\n",
    "\n",
    "data['review_sentiment'] = data['rating'].apply(lambda x: 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1769813f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "1769813f",
    "outputId": "ba96b606-9c96-4968-d1bf-5d3da6c98339"
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09059bf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "09059bf5",
    "outputId": "84e28763-8d87-4a3e-d32d-bee048fc6492"
   },
   "outputs": [],
   "source": [
    "# Plotting the pie chart for review sentiments\n",
    "\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.pie(data['review_sentiment'].value_counts(),labels=['Positive','Negative'],autopct='%1.1f%%')\n",
    "plt.title('Pie Chart representation of Review Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb376ce0",
   "metadata": {
    "id": "fb376ce0"
   },
   "source": [
    "- The positive reviews are 70% of the data. This is an imbalanced data.\n",
    "- Minority class need to be oversampled to overcome the problems of impbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2b151",
   "metadata": {
    "id": "0ac2b151"
   },
   "source": [
    "<b> Building the word cloud for positive and Negative Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ab1ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "451ab1ee",
    "outputId": "10fcdf79-ea15-484c-890d-bef364807937"
   },
   "outputs": [],
   "source": [
    "# word cloud for positive reviews\n",
    "\n",
    "positive_reviews = \" \".join([review for review in data['review'][data['review_sentiment'] == 1]])\n",
    "\n",
    "\n",
    "stop_words = set(STOPWORDS)\n",
    "\n",
    "wordcloud = WordCloud(width = 1200, height = 800,background_color ='white',stopwords = stop_words,min_font_size = 10).generate(positive_reviews)\n",
    "\n",
    "# plot the WordCloud image\n",
    "plt.figure(figsize = (12, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title('WordCloud for positive reviews')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93301974",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "93301974",
    "outputId": "e0eedb7b-c491-4b2e-ea15-142ebfa23f72",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# word cloud for negative reviews\n",
    "\n",
    "negative_reviews = \" \".join([review for review in data['review'][data['review_sentiment'] == 0]])\n",
    "\n",
    "wordcloud = WordCloud(width = 1200, height = 800,background_color ='white',stopwords = stop_words,min_font_size = 10).generate(negative_reviews)\n",
    "\n",
    "# plot the WordCloud image\n",
    "plt.figure(figsize = (12, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.title('WordCloud for negative reviews')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25771e2b",
   "metadata": {
    "id": "25771e2b"
   },
   "source": [
    "- In the wordclouds, we can see the frequent words are almost common in both the positive and negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c51f88",
   "metadata": {
    "id": "58c51f88"
   },
   "source": [
    "<b>Removing the conditions which are mentioned in above form</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bae3c7",
   "metadata": {
    "id": "e1bae3c7"
   },
   "outputs": [],
   "source": [
    "#this code is to remove the unwanted conditions in the above form.\n",
    "\n",
    "del_index = []\n",
    "conds =[]\n",
    "for c in data['condition']:\n",
    "    if ('helpful' in c) or ('Listed' in c):\n",
    "        f= list(data[data['condition']==c].index)\n",
    "        del_index.extend(f)\n",
    "        conds.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f7c57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a96f7c57",
    "outputId": "c524d1ee-0de0-410a-abd7-ecedec8bb1bb"
   },
   "outputs": [],
   "source": [
    "print('Size of the data before removing the conditions:',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ed40d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "817ed40d",
    "outputId": "29364dda-7197-4c46-8fcb-6a0afb660f11"
   },
   "outputs": [],
   "source": [
    "print('The removable conditions count is:',len(conds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eda972",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46eda972",
    "outputId": "da5a0154-4988-44e7-db97-b766baedaf32"
   },
   "outputs": [],
   "source": [
    "data.drop(del_index,inplace=True)\n",
    "print('Size of the data after dropping the condtions:',data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6eb4ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "7e6eb4ea",
    "outputId": "6395a7f0-cc58-44c6-9dc3-bcf07c39d1e9"
   },
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True,drop=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720f2ce",
   "metadata": {
    "id": "5720f2ce"
   },
   "source": [
    "<b>Preprocessing the Reviews</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8943b0",
   "metadata": {
    "id": "9e8943b0"
   },
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338fcbd8",
   "metadata": {
    "id": "338fcbd8"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text_data):\n",
    "\n",
    "    text_data = decontracted(text_data)\n",
    "\n",
    "    text_data = text_data.replace('\\n',' ')\n",
    "    text_data = text_data.replace('\\r',' ')\n",
    "    text_data = text_data.replace('\\t',' ')\n",
    "    text_data = text_data.replace('-',' ')\n",
    "    text_data = text_data.replace(\"/\",' ')\n",
    "    text_data = text_data.replace(\">\",' ')\n",
    "    text_data = text_data.replace('\"',' ')\n",
    "    text_data = text_data.replace('?',' ')\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x1QWHXPb9TBE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1QWHXPb9TBE",
    "outputId": "481dd62c-9ed0-4152-bcff-f2a296ada1e1"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a5d367",
   "metadata": {
    "id": "16a5d367"
   },
   "outputs": [],
   "source": [
    "# loading stop words from nltk library\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "#removing 'no' from the stop words list as there is an importance of 'side effects' and 'no side effects' in review\n",
    "stop_words.remove('no')\n",
    "\n",
    "def nlp_preprocessing(review):\n",
    "    '''This functional block preprocess the text data by removing digits, extra spaces, stop words\n",
    "    and converting words to lower case and stemming words'''\n",
    "\n",
    "    if type(review) is not int:\n",
    "        string = \"\"\n",
    "        review = preprocess_text(review)\n",
    "        review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "\n",
    "        review = re.sub('\\s+',' ', review)\n",
    "\n",
    "        review = review.lower()\n",
    "\n",
    "        for word in review.split():\n",
    "\n",
    "            if not word in stop_words:\n",
    "                word = stemmer.stem(word)\n",
    "                string += word + \" \"\n",
    "\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13e296",
   "metadata": {
    "id": "7a13e296"
   },
   "outputs": [],
   "source": [
    "data['cleaned_review'] = data['review'].apply(nlp_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4e359",
   "metadata": {
    "id": "e5b4e359"
   },
   "outputs": [],
   "source": [
    "# converting to lower case\n",
    "data['drugName'] = data['drugName'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0acd6e",
   "metadata": {
    "id": "ab0acd6e"
   },
   "outputs": [],
   "source": [
    "data['condition'] = data['condition'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4baadf4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "a4baadf4",
    "outputId": "e44fb524-2a06-4bdd-ff8a-712e2c03e88d"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc4a84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19bc4a84",
    "outputId": "f2c2dec9-ec52-4a9b-c4c7-a28612428195"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0941c95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0941c95",
    "outputId": "f93012d8-5198-4634-fce0-89d963923d9b"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99540459",
   "metadata": {
    "id": "99540459"
   },
   "outputs": [],
   "source": [
    "# adding the sentiment scores for reviews and preprocessed reviews as new features\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "data['sentiment_score'] = [sid.polarity_scores(v)['compound'] for v in data['review']]\n",
    "data['sentiment_score_clean'] = [sid.polarity_scores(v)['compound'] for v in data['cleaned_review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20882b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "e20882b1",
    "outputId": "27195c4a-06d8-4d4f-dc9c-aae64c34448e"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b738d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "de1b738d",
    "outputId": "485a245a-836b-4a4d-e7ab-60a7ae7dc561"
   },
   "outputs": [],
   "source": [
    "#checking the correlation of features\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cad77",
   "metadata": {
    "id": "e58cad77"
   },
   "outputs": [],
   "source": [
    "#data.to_csv('new_data_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6C5axNx3DC7H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6C5axNx3DC7H",
    "outputId": "76c8290e-0112-4638-bb5e-2a8f8b4af15a"
   },
   "outputs": [],
   "source": [
    "csv_data = data.to_csv(index=False)\n",
    "# Specify the file path and name for saving the CSV file\n",
    "file_path = '/content/drive/MyDrive/Python Practice/Prathamesh/DRUG RECOMMENDATION SYSTEM/csv_data.csv'\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(csv_data)\n",
    "print(\"CSV file saved successfully at\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c3df21",
   "metadata": {
    "id": "c3c3df21"
   },
   "source": [
    "- The useful features now are usefulCount, sentiment_score and sentiment_score_clean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c872f",
   "metadata": {
    "id": "c13c872f"
   },
   "source": [
    "<b>Conclusion:</b>\n",
    "<br>Based on the above analysis, the below are the important features to be used in next implementation stages:\n",
    "- condition - This feature can be used by performing labelencoding.\n",
    "- review - The new Feature extractions can be done from reviews before preprocessing like word count,char length, avg word count,stop word count etc..\n",
    "- date - New feature can be created with only year extraction and then label encoding, as we saw the analysis of year and count of reviews in respective years.\n",
    "- usefulCount - This feature is important from above correlation matrix.\n",
    "- cleaned_review - The preprocessed reviews are used after Vectorization using BoW , Tf-idf.\n",
    "- sentiment_score - This feature is important and is correlated with target feature closely.\n",
    "- sentiment_score_clean - This feature is important and is correlated with target feature closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f581d4",
   "metadata": {
    "id": "c9f581d4"
   },
   "source": [
    "<b>Next Steps</b>\n",
    "- Split the data to Train and Test.\n",
    "- Encode the categorical features\n",
    "- We need to vectorize the cleaned reviews using BoW, TF-IDF and also come up with few Feature extractions from reviews and cleaned reviews.\n",
    "- Normalize the numerical features.\n",
    "- Apply all the above encoded features to various classificatoin algorithms to come up with best models.\n",
    "<br>\n",
    "<b>Recommendation Approach </b>:\n",
    "- Select the best model from each of the different set of features applied while building the model (like best model with reviews encoded using Bow, best model with applying TF-IDF , best model with some extracted/important features extracted )\n",
    "- Add all the best model predicted values for each of the drug to get combined value and then multiply with usefulCount to create a new feature called recommendation score.\n",
    "- For each condition among the multiple available drugs, the drug with highest recommendation score is recommended.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
